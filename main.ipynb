{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUANTUM COMPUTING PROJECT: Historical Data Analysis\n",
      "================================================================================\n",
      "\n",
      "Libraries imported successfully!\n",
      "PennyLane version: 0.42.3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "QUANTUM COMPUTING PROJECT: Historical Data Analysis (using PennyLane)\n",
    "================================================================================\n",
    "\n",
    "This notebook demonstrates the power of quantum computing through:\n",
    "1. Classical ML (KNN/SVM): Predicting gladiator survival - explainable and beginner-friendly\n",
    "2. Data Integration: Connecting gladiator data with historical Wikipedia periods\n",
    "3. Quantum Optimization: Finding optimal groupings in historical Wikipedia data using \"QAOA\"\n",
    "\n",
    "Authors: Greg and Victor\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# PennyLane imports for quantum computing\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(777)\n",
    "pnp.random.seed(777)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"QUANTUM COMPUTING PROJECT: Historical Data Analysis\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nLibraries imported successfully!\")\n",
    "print(f\"PennyLane version: {qml.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e704307f",
   "metadata": {},
   "source": [
    "# Part 1: Data Loading and Exploration\n",
    "\n",
    "Let's start by loading and exploring our historical datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a987e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GLADIATOR DATASET OVERVIEW\n",
      "================================================================================\n",
      "Shape: (9976, 29)\n",
      "\n",
      "Columns: ['Name', 'Age', 'Birth Year', 'Origin', 'Height', 'Weight', 'Category', 'Wins', 'Losses', 'Special Skills', 'Weapon of Choice', 'Patron Wealth', 'Equipment Quality', 'Public Favor', 'Injury History', 'Mental Resilience', 'Diet and Nutrition', 'Tactical Knowledge', 'Allegiance Network', 'Battle Experience', 'Psychological Profile', 'Health Status', 'Personal Motivation', 'Previous Occupation', 'Training Intensity', 'Battle Strategy', 'Social Standing', 'Crowd Appeal Techniques', 'Survived']\n",
      "\n",
      "First few rows:\n",
      "                Name  Age  Birth Year Origin  Height  Weight     Category  \\\n",
      "0       Aelius Verus   32          97   Gaul     195      85       Thraex   \n",
      "1  Cocceius Galerius   20          32   Gaul     173      66  Hoplomachus   \n",
      "2      Pedius Furius   30          66   Gaul     170      67  Hoplomachus   \n",
      "3  Maximian Maecenas   28          43   Gaul     189     104  Hoplomachus   \n",
      "4    Celsus Laronius   41         126   Rome     173      85  Hoplomachus   \n",
      "\n",
      "   Wins  Losses Special Skills  ... Battle Experience Psychological Profile  \\\n",
      "0    11       4         Novice  ...                15               Fearful   \n",
      "1     7       2          Speed  ...                 9               Fearful   \n",
      "2     6       0        Tactics  ...                 6                 Stoic   \n",
      "3     6       2      Endurance  ...                 8           Calculative   \n",
      "4    12       4         Novice  ...                16           Calculative   \n",
      "\n",
      "  Health Status  Personal Motivation Previous Occupation  Training Intensity  \\\n",
      "0          Good                Glory          Unemployed              Medium   \n",
      "1     Excellent               Wealth            Criminal                High   \n",
      "2     Excellent              Freedom            Criminal                 Low   \n",
      "3     Excellent             Survival             Laborer                 Low   \n",
      "4          Fair             Survival          Unemployed                 Low   \n",
      "\n",
      "  Battle Strategy Social Standing Crowd Appeal Techniques  Survived  \n",
      "0        Balanced          Medium              Flamboyant     False  \n",
      "1        Balanced             Low                  Humble      True  \n",
      "2      Aggressive          Medium            Intimidating      True  \n",
      "3        Balanced             Low             Charismatic     False  \n",
      "4      Aggressive            High            Intimidating     False  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "Survival rate: 49.26%\n",
      "\n",
      "Missing values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Load the gladiator dataset\n",
    "# This dataset contains information about ancient Roman gladiators\n",
    "gladiator_df = pd.read_csv(\"gladiator_data.csv\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"GLADIATOR DATASET OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Shape: {gladiator_df.shape}\")\n",
    "print(f\"\\nColumns: {list(gladiator_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(gladiator_df.head())\n",
    "print(f\"\\nSurvival rate: {gladiator_df['Survived'].mean():.2%}\")\n",
    "print(f\"\\nMissing values:\\n{gladiator_df.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d552a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "WIKIPEDIA HISTORICAL DATASET OVERVIEW\n",
      "================================================================================\n",
      "Shape: (1077, 5)\n",
      "\n",
      "Columns: ['title', 'text', 'relevans', 'popularity', 'ranking']\n",
      "\n",
      "First few entries:\n",
      "                    title  relevans  popularity   ranking\n",
      "0          Westernization  0.815325    0.993961  0.810401\n",
      "1             Anachronism  0.810980    0.998420  0.809699\n",
      "2  Pre-industrial society  0.814736    0.993420  0.809376\n",
      "3           Periodization  0.811482    0.995228  0.807610\n",
      "4       History of Europe  0.804999    0.998863  0.804084\n",
      "5     Early modern period  0.801404    0.999153  0.800725\n",
      "6        Three-age system  0.801034    0.997677  0.799174\n",
      "7           Human history  0.799215    0.999453  0.798777\n",
      "8   Golden age (metaphor)  0.804347    0.992059  0.797959\n",
      "9       Industrialisation  0.799944    0.997364  0.797835\n",
      "\n",
      "Missing values:\n",
      "title         0\n",
      "text          0\n",
      "relevans      0\n",
      "popularity    0\n",
      "ranking       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the Wikipedia historical dataset\n",
    "wiki_df = pd.read_csv(\"wiki_data.csv\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"WIKIPEDIA HISTORICAL DATASET OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Shape: {wiki_df.shape}\")\n",
    "print(f\"\\nColumns: {list(wiki_df.columns)}\")\n",
    "print(f\"\\nFirst few entries:\")\n",
    "print(wiki_df[['title', 'relevans', 'popularity', 'ranking']].head(10))\n",
    "print(f\"\\nMissing values:\\n{wiki_df.isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5372c05b",
   "metadata": {},
   "source": [
    "# Part 2: Classical Machine Learning - Gladiator Survival Prediction\n",
    "\n",
    "## Overview\n",
    "We'll use **K-Nearest Neighbors (KNN)** and **Support Vector Machine (SVM)** to predict whether a gladiator survived based on their characteristics. These classical ML methods are more beginner-friendly and explainable than quantum classifiers.\n",
    "\n",
    "### Why KNN and SVM?\n",
    "- **KNN**: Simple, intuitive - predicts based on similar gladiators. Easy to explain: \"This gladiator survived because the 5 most similar gladiators also survived.\"\n",
    "- **SVM**: Finds optimal decision boundaries. Can visualize which features separate survivors from non-survivors.\n",
    "- **Explainability**: Both methods allow us to understand WHY predictions are made, unlike black-box models.\n",
    "\n",
    "### Key Concepts:\n",
    "- **K-Nearest Neighbors**: Classifies based on the k most similar training examples\n",
    "- **Support Vector Machine**: Finds the optimal hyperplane that best separates the classes\n",
    "- **Feature Importance**: Understanding which gladiator characteristics matter most for survival\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features for quantum circuit:\n",
      "1. Public Favor: correlation = 0.4672\n",
      "2. Wins: correlation = 0.3730\n",
      "3. Mental Resilience: correlation = 0.2813\n",
      "4. Battle Experience: correlation = 0.2607\n",
      "5. Equipment Quality_encoded: correlation = 0.1954\n",
      "6. Age: correlation = 0.1190\n",
      "7. Patron Wealth_encoded: correlation = 0.1051\n",
      "8. Losses: correlation = 0.0496\n",
      "\n",
      "Training set: 7980 samples\n",
      "Test set: 1996 samples\n",
      "Features per sample: 8\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA PREPROCESSING FOR CLASSICAL ML\n",
    "# ============================================================================\n",
    "\n",
    "# Select relevant numerical and categorical features for prediction\n",
    "# We'll use a mix of features that could influence survival\n",
    "\n",
    "# Numerical features\n",
    "numerical_features = ['Age', 'Height', 'Weight', 'Wins', 'Losses', \n",
    "                      'Public Favor', 'Mental Resilience', 'Battle Experience']\n",
    "\n",
    "# Categorical features to encode\n",
    "categorical_features = ['Category', 'Special Skills', 'Weapon of Choice', \n",
    "                        'Patron Wealth', 'Equipment Quality', 'Health Status']\n",
    "\n",
    "# Create a working copy\n",
    "df_work = gladiator_df.copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_work[col + '_encoded'] = le.fit_transform(df_work[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Combine features\n",
    "feature_cols = numerical_features + [col + '_encoded' for col in categorical_features]\n",
    "X = df_work[feature_cols].values\n",
    "y = df_work['Survived'].astype(int).values  # Convert True/False to 1/0\n",
    "\n",
    "# Normalize features (important for distance-based methods like KNN and SVM)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Analyze feature importance\n",
    "correlations = []\n",
    "for i, col in enumerate(feature_cols):\n",
    "    corr = np.abs(np.corrcoef(X[:, i], y)[0, 1])\n",
    "    correlations.append((i, corr, col))\n",
    "\n",
    "correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Feature correlations with survival:\")\n",
    "print(\"-\" * 60)\n",
    "for i, (idx, corr, name) in enumerate(correlations):\n",
    "    print(f\"{i+1:2d}. {name:30s}: {corr:.4f}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Features per sample: {X_train.shape[1]}\")\n",
    "print(f\"Survival rate (train): {y_train.mean():.2%}\")\n",
    "print(f\"Survival rate (test): {y_test.mean():.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d704a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum device: default.qubit\n",
      "Number of qubits: 8\n",
      "Number of layers: 2\n",
      "\n",
      "Weight shape: (2, 8, 3)\n",
      "Total trainable parameters: 48\n",
      "\n",
      "Sample output (expectation value): -0.3431\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# K-NEAREST NEIGHBORS (KNN) CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING K-NEAREST NEIGHBORS (KNN) CLASSIFIER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# KNN is simple: it finds the k most similar gladiators in the training set\n",
    "# and predicts based on what happened to those similar gladiators\n",
    "\n",
    "# Find optimal k using cross-validation\n",
    "print(\"\\nFinding optimal k value...\")\n",
    "k_range = range(3, 21, 2)\n",
    "k_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Simple cross-validation: train on subset, test on another\n",
    "    X_train_cv, X_val_cv, y_train_cv, y_val_cv = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    knn.fit(X_train_cv, y_train_cv)\n",
    "    score = knn.score(X_val_cv, y_val_cv)\n",
    "    k_scores.append(score)\n",
    "    if k % 5 == 0:\n",
    "        print(f\"  k={k:2d}: accuracy = {score:.4f}\")\n",
    "\n",
    "# Find best k\n",
    "best_k_idx = np.argmax(k_scores)\n",
    "best_k = list(k_range)[best_k_idx]\n",
    "print(f\"\\nBest k: {best_k} (accuracy: {k_scores[best_k_idx]:.4f})\")\n",
    "\n",
    "# Train final KNN model with best k\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"\\nKNN Test Accuracy: {accuracy_knn:.4f} ({accuracy_knn*100:.2f}%)\")\n",
    "\n",
    "# Explainability: Show which features matter most\n",
    "# We can look at which neighbors are found for a sample\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KNN EXPLAINABILITY EXAMPLE\")\n",
    "print(\"=\"*80)\n",
    "sample_idx = 0\n",
    "sample = X_test[sample_idx:sample_idx+1]\n",
    "distances, indices = knn_model.kneighbors(sample, n_neighbors=best_k)\n",
    "\n",
    "print(f\"\\nFor a test gladiator (predicted: {'Survived' if y_pred_knn[sample_idx] else 'Died'}):\")\n",
    "print(f\"The {best_k} most similar gladiators in training set:\")\n",
    "for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "    actual = \"Survived\" if y_train[idx] else \"Died\"\n",
    "    print(f\"  {i+1}. Distance: {dist:.3f}, Actual outcome: {actual}\")\n",
    "\n",
    "# Count how many neighbors survived\n",
    "neighbor_survivals = y_train[indices[0]].sum()\n",
    "print(f\"\\n{neighbor_survivals} out of {best_k} similar gladiators survived\")\n",
    "print(f\"Prediction: {'Survived' if neighbor_survivals > best_k/2 else 'Died'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c2fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum classifier model defined!\n",
      "Initial cost: 0.3018\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SUPPORT VECTOR MACHINE (SVM) CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING SUPPORT VECTOR MACHINE (SVM) CLASSIFIER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# SVM finds the optimal decision boundary (hyperplane) that best separates\n",
    "# survivors from non-survivors\n",
    "\n",
    "# Use a subset for faster training (SVM can be slow on large datasets)\n",
    "# In practice, you'd use the full dataset or a more efficient SVM implementation\n",
    "train_size = min(2000, len(X_train))\n",
    "X_train_svm = X_train[:train_size]\n",
    "y_train_svm = y_train[:train_size]\n",
    "\n",
    "print(f\"\\nTraining on {train_size} samples (for faster training)\")\n",
    "\n",
    "# Train SVM with RBF kernel\n",
    "# C: regularization parameter (higher = less regularization)\n",
    "# gamma: kernel coefficient (higher = more complex boundaries)\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True)\n",
    "svm_model.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"\\nSVM Test Accuracy: {accuracy_svm:.4f} ({accuracy_svm*100:.2f}%)\")\n",
    "\n",
    "# Explainability: Show support vectors and feature importance\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SVM EXPLAINABILITY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Number of support vectors: {len(svm_model.support_vectors_)}\")\n",
    "print(f\"Support vectors represent {len(svm_model.support_vectors_)/len(X_train_svm)*100:.1f}% of training data\")\n",
    "print(\"\\nSupport vectors are the 'critical' gladiators that define the decision boundary.\")\n",
    "print(\"These are the gladiators that are hardest to classify correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3a290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING QUANTUM CLASSIFIER\n",
      "================================================================================\n",
      "Epochs: 30\n",
      "Batch size: 20\n",
      "Training samples: 7980\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m     weights, bias = opt.step(batch_cost, weights, bias)\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Calculate cost\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     batch_cost_val = \u001b[43mbatch_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     epoch_cost += batch_cost_val\n\u001b[32m     52\u001b[39m avg_cost = epoch_cost / n_batches\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mbatch_cost\u001b[39m\u001b[34m(w, b)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbatch_cost\u001b[39m(w, b):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcost_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mcost_function\u001b[39m\u001b[34m(weights, bias, X, y)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcost_function\u001b[39m(weights, bias, X, y):\n\u001b[32m     25\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03m    Cost function for training the quantum classifier.\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Uses mean squared error between predictions and true labels.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m \u001b[33;03m        Mean squared error\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     predictions = [\u001b[43mquantum_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[32m     39\u001b[39m     predictions = pnp.array(predictions)\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Convert quantum output [-1, 1] to probability [0, 1]\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# Using sigmoid-like transformation: (x + 1) / 2\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mquantum_classifier\u001b[39m\u001b[34m(weights, bias, features)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03mQuantum classifier that combines quantum circuit output with classical bias.\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33;03m    Prediction value (before sigmoid activation)\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Get quantum circuit output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m quantum_output = \u001b[43mquantum_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Combine with bias and return\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# The quantum output is in [-1, 1], we scale it and add bias\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m quantum_output + bias\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/workflow/qnode.py:922\u001b[39m, in \u001b[36mQNode.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_capture_qnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/workflow/qnode.py:895\u001b[39m, in \u001b[36mQNode._impl_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[32m    893\u001b[39m \u001b[38;5;28mself\u001b[39m._transform_program.set_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m res = \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    904\u001b[39m res = res[\u001b[32m0\u001b[39m]\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/workflow/execution.py:233\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(tapes, device, diff_method, interface, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, transform_program, executor_backend)\u001b[39m\n\u001b[32m    229\u001b[39m tapes, outer_post_processing = outer_transform(tapes)\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outer_transform.is_informative, \u001b[33m\"\u001b[39m\u001b[33mshould only contain device preprocessing\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m results = \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m user_post_processing(outer_post_processing(results))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/workflow/run.py:291\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(tapes, device, config, inner_transform_program)\u001b[39m\n\u001b[32m    287\u001b[39m no_interface_boundary_required = (\n\u001b[32m    288\u001b[39m     config.interface == Interface.NUMPY \u001b[38;5;129;01mor\u001b[39;00m config.gradient_method == \u001b[33m\"\u001b[39m\u001b[33mbackprop\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    289\u001b[39m )\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m no_interface_boundary_required:\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     results = \u001b[43minner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# TODO: Prune once support for tf-autograph is dropped\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/workflow/run.py:256\u001b[39m, in \u001b[36m_make_inner_execute.<locals>.inner_execute\u001b[39m\u001b[34m(tapes)\u001b[39m\n\u001b[32m    253\u001b[39m transformed_tapes, transform_post_processing = inner_transform(tapes)\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     results = \u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_tapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    258\u001b[39m     results = ()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/devices/modifiers/simulator_tracking.py:28\u001b[39m, in \u001b[36m_track_execute.<locals>.execute\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(untracked_execute)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, circuits, execution_config=DefaultExecutionConfig):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     results = \u001b[43muntracked_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(circuits, QuantumScript):\n\u001b[32m     30\u001b[39m         batch = (circuits,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/devices/modifiers/single_tape_support.py:30\u001b[39m, in \u001b[36m_make_execute.<locals>.execute\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m     28\u001b[39m     is_single_circuit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     29\u001b[39m     circuits = (circuits,)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m results = \u001b[43mbatch_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/logging/decorators.py:61\u001b[39m, in \u001b[36mlog_string_debug_func.<locals>.wrapper_entry\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m     s_caller = \u001b[33m\"\u001b[39m\u001b[33m::L\u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m     55\u001b[39m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect.getouterframes(inspect.currentframe(), \u001b[32m2\u001b[39m)[\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m:\u001b[32m3\u001b[39m]]\n\u001b[32m     56\u001b[39m     )\n\u001b[32m     57\u001b[39m     lgr.debug(\n\u001b[32m     58\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m         **_debug_log_kwargs,\n\u001b[32m     60\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/devices/default_qubit.py:707\u001b[39m, in \u001b[36mDefaultQubit.execute\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m    697\u001b[39m     warnings.warn(\n\u001b[32m    698\u001b[39m         (\n\u001b[32m    699\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mJitting executions with many circuits may have substantial classical overhead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    702\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    703\u001b[39m     )\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_simulate_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m            \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdebugger\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_debugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minterface\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstate_cache\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprng_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmcm_method\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmcm_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmcm_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpostselect_mode\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmcm_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpostselect_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprng_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    723\u001b[39m vanilla_circuits = convert_to_numpy_parameters(circuits)[\u001b[32m0\u001b[39m]\n\u001b[32m    724\u001b[39m seeds = \u001b[38;5;28mself\u001b[39m._rng.integers(\u001b[32m2\u001b[39m**\u001b[32m31\u001b[39m - \u001b[32m1\u001b[39m, size=\u001b[38;5;28mlen\u001b[39m(vanilla_circuits))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/devices/default_qubit.py:708\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    697\u001b[39m     warnings.warn(\n\u001b[32m    698\u001b[39m         (\n\u001b[32m    699\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mJitting executions with many circuits may have substantial classical overhead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    702\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    703\u001b[39m     )\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m         \u001b[43m_simulate_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m            \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdebugger\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_debugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minterface\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstate_cache\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprng_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmcm_method\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmcm_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmcm_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpostselect_mode\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmcm_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpostselect_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m c, _key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(circuits, prng_keys)\n\u001b[32m    721\u001b[39m     )\n\u001b[32m    723\u001b[39m vanilla_circuits = convert_to_numpy_parameters(circuits)[\u001b[32m0\u001b[39m]\n\u001b[32m    724\u001b[39m seeds = \u001b[38;5;28mself\u001b[39m._rng.integers(\u001b[32m2\u001b[39m**\u001b[32m31\u001b[39m - \u001b[32m1\u001b[39m, size=\u001b[38;5;28mlen\u001b[39m(vanilla_circuits))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/devices/default_qubit.py:1055\u001b[39m, in \u001b[36m_simulate_wrapper\u001b[39m\u001b[34m(circuit, kwargs)\u001b[39m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_simulate_wrapper\u001b[39m(circuit, kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/logging/decorators.py:61\u001b[39m, in \u001b[36mlog_string_debug_func.<locals>.wrapper_entry\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m     s_caller = \u001b[33m\"\u001b[39m\u001b[33m::L\u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m     55\u001b[39m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect.getouterframes(inspect.currentframe(), \u001b[32m2\u001b[39m)[\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m:\u001b[32m3\u001b[39m]]\n\u001b[32m     56\u001b[39m     )\n\u001b[32m     57\u001b[39m     lgr.debug(\n\u001b[32m     58\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m         **_debug_log_kwargs,\n\u001b[32m     60\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/devices/qubit/simulate.py:359\u001b[39m, in \u001b[36msimulate\u001b[39m\u001b[34m(circuit, debugger, state_cache, **execution_kwargs)\u001b[39m\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(results)\n\u001b[32m    358\u001b[39m ops_key, meas_key = jax_random_split(prng_key)\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m state, is_state_batched = \u001b[43mget_final_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebugger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mops_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mexecution_kwargs\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    363\u001b[39m     state_cache[circuit.hash] = state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/logging/decorators.py:61\u001b[39m, in \u001b[36mlog_string_debug_func.<locals>.wrapper_entry\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m     s_caller = \u001b[33m\"\u001b[39m\u001b[33m::L\u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m     55\u001b[39m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect.getouterframes(inspect.currentframe(), \u001b[32m2\u001b[39m)[\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m:\u001b[32m3\u001b[39m]]\n\u001b[32m     56\u001b[39m     )\n\u001b[32m     57\u001b[39m     lgr.debug(\n\u001b[32m     58\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m         **_debug_log_kwargs,\n\u001b[32m     60\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/devices/qubit/simulate.py:192\u001b[39m, in \u001b[36mget_final_state\u001b[39m\u001b[34m(circuit, debugger, **execution_kwargs)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, MidMeasureMP):\n\u001b[32m    191\u001b[39m     prng_key, key = jax_random_split(prng_key)\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m state = \u001b[43mapply_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtape_shots\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mexecution_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# Handle postselection on mid-circuit measurements\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, qml.Projector):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/functools.py:934\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    933\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/devices/qubit/apply_operation.py:232\u001b[39m, in \u001b[36mapply_operation\u001b[39m\u001b[34m(op, state, is_state_batched, debugger, **_)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;129m@singledispatch\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_operation\u001b[39m(\n\u001b[32m    168\u001b[39m     op: qml.operation.Operator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m     **_,\n\u001b[32m    173\u001b[39m ):\n\u001b[32m    174\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply and operator to a given state.\u001b[39;00m\n\u001b[32m    175\u001b[39m \n\u001b[32m    176\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m \n\u001b[32m    231\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_operation_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/devices/qubit/apply_operation.py:258\u001b[39m, in \u001b[36m_apply_operation_default\u001b[39m\u001b[34m(op, state, is_state_batched, debugger)\u001b[39m\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_operation_csr_matrix(op, state, is_state_batched=is_state_batched)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mlen\u001b[39m(op.wires) < EINSUM_OP_WIRECOUNT_PERF_THRESHOLD\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m math.ndim(state) < EINSUM_STATE_WIRECOUNT_PERF_THRESHOLD\n\u001b[32m    257\u001b[39m ) \u001b[38;5;129;01mor\u001b[39;00m (op.batch_size \u001b[38;5;129;01mand\u001b[39;00m is_state_batched):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_operation_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m apply_operation_tensordot(op, state, is_state_batched=is_state_batched)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/devices/qubit/apply_operation.py:81\u001b[39m, in \u001b[36mapply_operation_einsum\u001b[39m\u001b[34m(op, state, is_state_batched)\u001b[39m\n\u001b[32m     79\u001b[39m     mat = qml.math.cast_like(op.matrix(), state)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     mat = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m + \u001b[32m0\u001b[39mj\n\u001b[32m     83\u001b[39m total_indices = \u001b[38;5;28mlen\u001b[39m(state.shape) - is_state_batched\n\u001b[32m     84\u001b[39m num_indices = \u001b[38;5;28mlen\u001b[39m(op.wires)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/operation.py:945\u001b[39m, in \u001b[36mOperator.matrix\u001b[39m\u001b[34m(self, wire_order)\u001b[39m\n\u001b[32m    925\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmatrix\u001b[39m(\u001b[38;5;28mself\u001b[39m, wire_order: Optional[WiresLike] = \u001b[38;5;28;01mNone\u001b[39;00m) -> TensorLike:\n\u001b[32m    926\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Representation of the operator as a matrix in the computational basis.\u001b[39;00m\n\u001b[32m    927\u001b[39m \n\u001b[32m    928\u001b[39m \u001b[33;03m    If ``wire_order`` is provided, the numerical representation considers the position of the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    943\u001b[39m \u001b[33;03m        tensor_like: matrix representation\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     canonical_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    948\u001b[39m         wire_order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    949\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.wires == Wires(wire_order)\n\u001b[32m   (...)\u001b[39m\u001b[32m    953\u001b[39m         )\n\u001b[32m    954\u001b[39m     ):\n\u001b[32m    955\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m canonical_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/ops/qubit/parametric_ops_single_qubit.py:936\u001b[39m, in \u001b[36mRot.compute_matrix\u001b[39m\u001b[34m(phi, theta, omega)\u001b[39m\n\u001b[32m    930\u001b[39m c = c * one\n\u001b[32m    931\u001b[39m s = s * one\n\u001b[32m    933\u001b[39m mat = [\n\u001b[32m    934\u001b[39m     [\n\u001b[32m    935\u001b[39m         qml.math.exp(-\u001b[32m0.5\u001b[39mj * (phi + omega)) * c,\n\u001b[32m--> \u001b[39m\u001b[32m936\u001b[39m         -qml.math.exp(\u001b[32;43m0.5\u001b[39;49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43momega\u001b[49m\u001b[43m)\u001b[49m) * s,\n\u001b[32m    937\u001b[39m     ],\n\u001b[32m    938\u001b[39m     [\n\u001b[32m    939\u001b[39m         qml.math.exp(-\u001b[32m0.5\u001b[39mj * (phi - omega)) * s,\n\u001b[32m    940\u001b[39m         qml.math.exp(\u001b[32m0.5\u001b[39mj * (phi + omega)) * c,\n\u001b[32m    941\u001b[39m     ],\n\u001b[32m    942\u001b[39m ]\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m qml.math.stack([stack_last(row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m mat], axis=-\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/quantum_computing/lib/python3.13/site-packages/pennylane/numpy/tensor.py:152\u001b[39m, in \u001b[36mtensor.__array_ufunc__\u001b[39m\u001b[34m(self, ufunc, method, *inputs, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m args = [i.unwrap() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(i, \u001b[33m\"\u001b[39m\u001b[33munwrap\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# call the ndarray.__array_ufunc__ method to compute the result\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# of the vectorized ufunc\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m res = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__array_ufunc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ufunc.nout == \u001b[32m1\u001b[39m:\n\u001b[32m    155\u001b[39m     res = (res,)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MODEL COMPARISON AND EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compare both models\n",
    "baseline_accuracy = max(y_test.mean(), 1 - y_test.mean())\n",
    "\n",
    "print(f\"\\nBaseline (majority class): {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")\n",
    "print(f\"KNN Accuracy:              {accuracy_knn:.4f} ({accuracy_knn*100:.2f}%)\")\n",
    "print(f\"SVM Accuracy:              {accuracy_svm:.4f} ({accuracy_svm*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nKNN Improvement over baseline: {accuracy_knn - baseline_accuracy:.4f}\")\n",
    "print(f\"SVM Improvement over baseline: {accuracy_svm - baseline_accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification reports\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KNN CLASSIFICATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred_knn, target_names=['Died', 'Survived']))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SVM CLASSIFICATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred_svm, target_names=['Died', 'Survived']))\n",
    "\n",
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# KNN confusion matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Died', 'Survived'],\n",
    "            yticklabels=['Died', 'Survived'])\n",
    "axes[0].set_title(f'KNN Confusion Matrix\\n(Accuracy: {accuracy_knn:.2%})', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label', fontsize=10)\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=10)\n",
    "\n",
    "# SVM confusion matrix\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Oranges', ax=axes[1],\n",
    "            xticklabels=['Died', 'Survived'],\n",
    "            yticklabels=['Died', 'Survived'])\n",
    "axes[1].set_title(f'SVM Confusion Matrix\\n(Accuracy: {accuracy_svm:.2%})', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('True Label', fontsize=10)\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f019f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONNECTING GLADIATOR DATA WITH HISTORICAL PERIODS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONNECTING DATASETS: GLADIATORS AND HISTORICAL PERIODS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use gladiator birth years to connect with historical periods from wiki data\n",
    "# We'll analyze survival rates by historical era\n",
    "\n",
    "# Define historical periods based on Roman history\n",
    "def get_historical_period(birth_year):\n",
    "    \"\"\"Map birth year to historical period.\"\"\"\n",
    "    if birth_year < 27:  # Before Augustus\n",
    "        return \"Roman Republic (Before 27 BCE)\"\n",
    "    elif birth_year < 180:  # Before Commodus\n",
    "        return \"Early Empire (27 BCE - 180 CE)\"\n",
    "    elif birth_year < 284:  # Before Diocletian\n",
    "        return \"Crisis Period (180-284 CE)\"\n",
    "    else:\n",
    "        return \"Late Empire (284+ CE)\"\n",
    "\n",
    "# Add historical period to gladiator data\n",
    "gladiator_df['Historical Period'] = gladiator_df['Birth Year'].apply(get_historical_period)\n",
    "\n",
    "# Analyze survival rates by period\n",
    "period_analysis = gladiator_df.groupby('Historical Period').agg({\n",
    "    'Survived': ['mean', 'count']\n",
    "}).round(4)\n",
    "period_analysis.columns = ['Survival Rate', 'Count']\n",
    "period_analysis = period_analysis.sort_values('Survival Rate', ascending=False)\n",
    "\n",
    "print(\"\\nSurvival Rates by Historical Period:\")\n",
    "print(\"-\" * 60)\n",
    "for period, row in period_analysis.iterrows():\n",
    "    print(f\"{period:35s}: {row['Survival Rate']:.2%} ({int(row['Count'])} gladiators)\")\n",
    "\n",
    "# Visualize survival by period\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Survival rate by period\n",
    "periods = period_analysis.index\n",
    "survival_rates = period_analysis['Survival Rate'].values\n",
    "colors = ['#2ecc71' if rate > 0.5 else '#e74c3c' for rate in survival_rates]\n",
    "\n",
    "axes[0].barh(range(len(periods)), survival_rates, color=colors, alpha=0.7)\n",
    "axes[0].set_yticks(range(len(periods)))\n",
    "axes[0].set_yticklabels([p.split('(')[0].strip() for p in periods], fontsize=9)\n",
    "axes[0].axvline(x=0.5, color='black', linestyle='--', alpha=0.5, label='50% baseline')\n",
    "axes[0].set_xlabel('Survival Rate', fontsize=11)\n",
    "axes[0].set_title('Gladiator Survival Rate by Historical Period', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Count of gladiators by period\n",
    "counts = period_analysis['Count'].values\n",
    "axes[1].bar(range(len(periods)), counts, color='steelblue', alpha=0.7)\n",
    "axes[1].set_xticks(range(len(periods)))\n",
    "axes[1].set_xticklabels([p.split('(')[0].strip() for p in periods], rotation=45, ha='right', fontsize=9)\n",
    "axes[1].set_ylabel('Number of Gladiators', fontsize=11)\n",
    "axes[1].set_title('Number of Gladiators by Historical Period', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find relevant Wikipedia topics for these periods\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RELEVANT HISTORICAL TOPICS FROM WIKIPEDIA DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Search for topics related to Roman history\n",
    "roman_keywords = ['roman', 'empire', 'republic', 'gladiator', 'ancient', 'history']\n",
    "relevant_topics = wiki_df[wiki_df['title'].str.lower().str.contains('|'.join(roman_keywords), na=False)]\n",
    "\n",
    "print(f\"\\nFound {len(relevant_topics)} Wikipedia topics related to Roman history:\")\n",
    "print(\"-\" * 60)\n",
    "for idx, row in relevant_topics.head(10).iterrows():\n",
    "    print(f\"   {row['title']} (popularity: {row['popularity']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INSIGHT: We can see how gladiator survival rates varied across different\")\n",
    "print(\"historical periods, and connect this to the historical context from\")\n",
    "print(\"Wikipedia data. This demonstrates how combining datasets provides\")\n",
    "print(\"deeper insights than using them separately!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0830b1",
   "metadata": {},
   "source": [
    "# Part 3: Quantum Optimization - Finding Optimal Historical Topic Groupings\n",
    "\n",
    "## Overview\n",
    "We'll use the **Quantum Approximate Optimization Algorithm (QAOA)** to find optimal groupings of historical Wikipedia topics. This demonstrates how quantum computers can solve combinatorial optimization problems.\n",
    "\n",
    "### Key Concepts:\n",
    "- **QAOA**: A quantum algorithm for solving optimization problems\n",
    "- **Max-Cut Problem**: Finding optimal partitions in a graph (we'll create a graph from topic similarities)\n",
    "- **Cost Hamiltonian**: Quantum representation of the optimization objective\n",
    "- **Variational Optimization**: Finding optimal parameters through classical optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e37d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PREPARING DATA FOR QUANTUM OPTIMIZATION\n",
    "# ============================================================================\n",
    "\n",
    "# For QAOA, we'll work with a smaller subset of Wikipedia entries\n",
    "# QAOA works best with smaller graphs (due to current quantum hardware limitations)\n",
    "n_topics = 20  # Number of topics to cluster\n",
    "\n",
    "# Select top N topics by popularity/ranking\n",
    "wiki_subset = wiki_df.nlargest(n_topics, 'popularity').copy()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"QUANTUM OPTIMIZATION: Historical Topic Clustering\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Selected {n_topics} topics for optimization\")\n",
    "print(f\"\\nSelected topics:\")\n",
    "for i, title in enumerate(wiki_subset['title'].head(10), 1):\n",
    "    print(f\"{i}. {title}\")\n",
    "\n",
    "# Create a similarity graph based on text content\n",
    "# We'll use simple keyword matching to create edges\n",
    "# In practice, you could use more sophisticated NLP techniques\n",
    "\n",
    "# Extract keywords from titles (simple approach)\n",
    "def extract_keywords(text):\n",
    "    \"\"\"Extract keywords from text (simplified).\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # Convert to lowercase and split\n",
    "    words = str(text).lower().split()\n",
    "    # Filter out very short words\n",
    "    keywords = [w for w in words if len(w) > 3]\n",
    "    return set(keywords)\n",
    "\n",
    "# Build similarity matrix\n",
    "similarity_matrix = np.zeros((n_topics, n_topics))\n",
    "\n",
    "for i in range(n_topics):\n",
    "    keywords_i = extract_keywords(wiki_subset.iloc[i]['title'])\n",
    "    for j in range(i + 1, n_topics):\n",
    "        keywords_j = extract_keywords(wiki_subset.iloc[j]['title'])\n",
    "        # Jaccard similarity\n",
    "        intersection = len(keywords_i & keywords_j)\n",
    "        union = len(keywords_i | keywords_j)\n",
    "        similarity = intersection / union if union > 0 else 0\n",
    "        similarity_matrix[i, j] = similarity\n",
    "        similarity_matrix[j, i] = similarity\n",
    "\n",
    "# Create adjacency matrix for graph\n",
    "# Connect topics with similarity > threshold\n",
    "threshold = 0.1\n",
    "adjacency_matrix = (similarity_matrix > threshold).astype(int)\n",
    "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
    "\n",
    "# Count edges\n",
    "n_edges = np.sum(adjacency_matrix) // 2\n",
    "print(f\"\\nGraph statistics:\")\n",
    "print(f\"  Nodes (topics): {n_topics}\")\n",
    "print(f\"  Edges (connections): {n_edges}\")\n",
    "print(f\"  Average degree: {np.sum(adjacency_matrix) / n_topics:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70224d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QAOA IMPLEMENTATION FOR MAX-CUT PROBLEM\n",
    "# ============================================================================\n",
    "\n",
    "# Max-Cut Problem: Partition graph into two groups to maximize edges between groups\n",
    "# This is a classic optimization problem that QAOA can solve efficiently\n",
    "\n",
    "# Create quantum device\n",
    "n_qubits_opt = n_topics\n",
    "dev_opt = qml.device('default.qubit', wires=n_qubits_opt)\n",
    "\n",
    "def maxcut_cost_hamiltonian(adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Create the cost Hamiltonian for Max-Cut problem.\n",
    "    \n",
    "    Max-Cut: Maximize the number of edges between two partitions.\n",
    "    Cost Hamiltonian: Sum over edges (1 - Z_i Z_j) / 2\n",
    "    where Z_i, Z_j are Pauli-Z operators on qubits i and j\n",
    "    \n",
    "    Args:\n",
    "        adjacency_matrix: Graph adjacency matrix\n",
    "    \n",
    "    Returns:\n",
    "        Cost Hamiltonian as a PennyLane observable and list of edges\n",
    "    \"\"\"\n",
    "    # List of observables (one for each edge)\n",
    "    observables = []\n",
    "    coeffs = []\n",
    "    edges = []  # Store edges for easier circuit construction\n",
    "    \n",
    "    for i in range(n_qubits_opt):\n",
    "        for j in range(i + 1, n_qubits_opt):\n",
    "            if adjacency_matrix[i, j] == 1:  # If there's an edge\n",
    "                # Cost for edge (i,j): (1 - Z_i Z_j) / 2\n",
    "                # We want to maximize this, so minimize its negative\n",
    "                obs = qml.PauliZ(i) @ qml.PauliZ(j)\n",
    "                observables.append(obs)\n",
    "                coeffs.append(-0.5)  # Negative because we'll minimize\n",
    "                edges.append((i, j))\n",
    "    \n",
    "    # Constant term (doesn't affect optimization)\n",
    "    constant = np.sum(adjacency_matrix) / 2\n",
    "    \n",
    "    return qml.Hamiltonian(coeffs, observables), constant, edges\n",
    "\n",
    "# Create cost Hamiltonian\n",
    "cost_hamiltonian, constant, edges = maxcut_cost_hamiltonian(adjacency_matrix)\n",
    "\n",
    "print(f\"Cost Hamiltonian created with {len(edges)} terms (edges)\")\n",
    "print(f\"Constant term: {constant}\")\n",
    "\n",
    "def mixer_hamiltonian(n_qubits):\n",
    "    \"\"\"\n",
    "    Create the mixer Hamiltonian for QAOA.\n",
    "    Mixer: Sum of Pauli-X operators on all qubits\n",
    "    This allows the algorithm to explore the solution space.\n",
    "    \n",
    "    Args:\n",
    "        n_qubits: Number of qubits\n",
    "    \n",
    "    Returns:\n",
    "        Mixer Hamiltonian\n",
    "    \"\"\"\n",
    "    coeffs = []\n",
    "    observables = []\n",
    "    for i in range(n_qubits):\n",
    "        coeffs.append(1.0)\n",
    "        observables.append(qml.PauliX(i))\n",
    "    return qml.Hamiltonian(coeffs, observables)\n",
    "\n",
    "mixer_hamiltonian = mixer_hamiltonian(n_qubits_opt)\n",
    "print(f\"Mixer Hamiltonian created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QAOA CIRCUIT\n",
    "# ============================================================================\n",
    "\n",
    "def qaoa_layer(gamma, beta, edges_list):\n",
    "    \"\"\"\n",
    "    One layer of QAOA circuit.\n",
    "    \n",
    "    QAOA alternates between:\n",
    "    1. Applying cost Hamiltonian (with parameter gamma)\n",
    "    2. Applying mixer Hamiltonian (with parameter beta)\n",
    "    \n",
    "    Args:\n",
    "        gamma: Parameter for cost Hamiltonian evolution\n",
    "        beta: Parameter for mixer Hamiltonian evolution\n",
    "        edges_list: List of edges (i, j) in the graph\n",
    "    \"\"\"\n",
    "    # Apply cost Hamiltonian evolution\n",
    "    # Our cost Hamiltonian is: H = sum over edges (-0.5 * Z_i * Z_j)\n",
    "    # We want to apply: exp(-i*gamma*H) = exp(i*gamma*0.5*sum(Z_i*Z_j))\n",
    "    # For each edge, apply exp(i*gamma*0.5*Z_i*Z_j)\n",
    "    # Using CNOT-RZ-CNOT decomposition: exp(i*theta*Z_i*Z_j) = CNOT RZ(-2*theta) CNOT\n",
    "    for i, j in edges_list:\n",
    "        # CNOT-RZ-CNOT decomposition for exp(i*gamma*0.5*Z_i*Z_j)\n",
    "        # theta = gamma*0.5, so rotation angle = -2*theta = -gamma\n",
    "        qml.CNOT(wires=[i, j])\n",
    "        qml.RZ(-gamma, wires=j)\n",
    "        qml.CNOT(wires=[i, j])\n",
    "    \n",
    "    # Apply mixer Hamiltonian evolution\n",
    "    # Mixer is sum of Pauli-X: exp(-i*beta*sum(X_i)) = product of RX(2*beta)\n",
    "    for i in range(n_qubits_opt):\n",
    "        qml.RX(2 * beta, wires=i)\n",
    "\n",
    "def qaoa_circuit(params, cost_ham, mixer_ham):\n",
    "    \"\"\"\n",
    "    Full QAOA circuit.\n",
    "    \n",
    "    Args:\n",
    "        params: Array of parameters [gamma_1, beta_1, gamma_2, beta_2, ...]\n",
    "        cost_ham: Cost Hamiltonian (for measurement)\n",
    "        mixer_ham: Mixer Hamiltonian (not used directly, kept for API consistency)\n",
    "    \n",
    "    Returns:\n",
    "        Expectation value of cost Hamiltonian\n",
    "    \"\"\"\n",
    "    # Initialize in uniform superposition |+^n\n",
    "    for i in range(n_qubits_opt):\n",
    "        qml.Hadamard(wires=i)\n",
    "    \n",
    "    # Apply QAOA layers\n",
    "    p = len(params) // 2  # Number of layers\n",
    "    for i in range(p):\n",
    "        gamma = params[2 * i]\n",
    "        beta = params[2 * i + 1]\n",
    "        qaoa_layer(gamma, beta, edges)\n",
    "    \n",
    "    # Measure expectation value of cost Hamiltonian\n",
    "    return qml.expval(cost_ham)\n",
    "\n",
    "# Create QAOA QNode\n",
    "qaoa_qnode = qml.QNode(qaoa_circuit, dev_opt)\n",
    "\n",
    "# Number of QAOA layers (depth)\n",
    "p = 2  # More layers = better approximation, but more parameters to optimize\n",
    "\n",
    "# Initialize parameters randomly\n",
    "init_params = pnp.random.uniform(0, 2 * np.pi, size=2 * p, requires_grad=True)\n",
    "\n",
    "print(f\"QAOA circuit created\")\n",
    "print(f\"  Number of layers (p): {p}\")\n",
    "print(f\"  Number of parameters: {len(init_params)}\")\n",
    "print(f\"  Initial parameters: {init_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIMIZING QAOA PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "def qaoa_cost(params):\n",
    "    \"\"\"\n",
    "    Cost function for QAOA optimization.\n",
    "    We want to minimize the expectation value of the cost Hamiltonian.\n",
    "    \n",
    "    Args:\n",
    "        params: QAOA parameters\n",
    "    \n",
    "    Returns:\n",
    "        Expectation value (to be minimized)\n",
    "    \"\"\"\n",
    "    return qaoa_qnode(params, cost_hamiltonian, mixer_hamiltonian)\n",
    "\n",
    "# Optimize QAOA parameters\n",
    "opt_qaoa = qml.AdamOptimizer(stepsize=0.1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"OPTIMIZING QAOA PARAMETERS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "n_iterations = 50\n",
    "params = init_params\n",
    "cost_history_qaoa = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Optimize\n",
    "    params, cost_val = opt_qaoa.step_and_cost(qaoa_cost, params)\n",
    "    cost_history_qaoa.append(cost_val)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Iteration {i + 1}/{n_iterations}, Cost: {cost_val:.4f}\")\n",
    "\n",
    "print(\"\\nOptimization completed!\")\n",
    "print(f\"Final cost: {cost_history_qaoa[-1]:.4f}\")\n",
    "\n",
    "# Plot optimization history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cost_history_qaoa, 'r-', linewidth=2)\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Cost (Expectation Value)', fontsize=12)\n",
    "plt.title('QAOA Optimization History', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXTRACTING OPTIMAL SOLUTION\n",
    "# ============================================================================\n",
    "\n",
    "# Sample from the optimized QAOA circuit to get the solution\n",
    "n_samples = 1000\n",
    "\n",
    "def sample_solution(params, n_samples):\n",
    "    \"\"\"\n",
    "    Sample bitstrings from QAOA circuit and find the best solution.\n",
    "    \n",
    "    Args:\n",
    "        params: Optimized QAOA parameters\n",
    "        n_samples: Number of samples to draw\n",
    "    \n",
    "    Returns:\n",
    "        Best bitstring and its cost\n",
    "    \"\"\"\n",
    "    # Create a circuit that measures in computational basis\n",
    "    @qml.qnode(dev_opt)\n",
    "    def measurement_circuit(params):\n",
    "        # Apply QAOA circuit\n",
    "        for i in range(n_qubits_opt):\n",
    "            qml.Hadamard(wires=i)\n",
    "        \n",
    "        p = len(params) // 2\n",
    "        for i in range(p):\n",
    "            gamma = params[2 * i]\n",
    "            beta = params[2 * i + 1]\n",
    "            qaoa_layer(gamma, beta, edges)\n",
    "        \n",
    "        # Measure all qubits\n",
    "        return [qml.sample(qml.PauliZ(i)) for i in range(n_qubits_opt)]\n",
    "    \n",
    "    # Sample bitstrings\n",
    "    samples = []\n",
    "    for _ in range(n_samples):\n",
    "        sample = measurement_circuit(params)\n",
    "        # Convert from {-1, +1} to {0, 1}\n",
    "        bitstring = [(1 - s) // 2 for s in sample]\n",
    "        samples.append(bitstring)\n",
    "    \n",
    "    # Calculate cost for each sample\n",
    "    def calculate_cut_cost(bitstring):\n",
    "        \"\"\"Calculate the cut value for a given partition.\"\"\"\n",
    "        cut_value = 0\n",
    "        for i in range(n_qubits_opt):\n",
    "            for j in range(i + 1, n_qubits_opt):\n",
    "                if adjacency_matrix[i, j] == 1:\n",
    "                    # Edge is cut if nodes are in different partitions\n",
    "                    if bitstring[i] != bitstring[j]:\n",
    "                        cut_value += 1\n",
    "        return cut_value\n",
    "    \n",
    "    # Find best solution\n",
    "    best_bitstring = None\n",
    "    best_cost = -1\n",
    "    \n",
    "    for bitstring in samples:\n",
    "        cost = calculate_cut_cost(bitstring)\n",
    "        if cost > best_cost:\n",
    "            best_cost = cost\n",
    "            best_bitstring = bitstring\n",
    "    \n",
    "    return best_bitstring, best_cost\n",
    "\n",
    "print(\"Sampling solutions from optimized QAOA circuit...\")\n",
    "best_solution, best_cut_value = sample_solution(params, n_samples)\n",
    "\n",
    "print(f\"\\nOptimal partition found!\")\n",
    "print(f\"Cut value (edges between partitions): {best_cut_value} out of {n_edges} total edges\")\n",
    "print(f\"Cut ratio: {best_cut_value / n_edges:.2%}\")\n",
    "\n",
    "# Display the partition\n",
    "group_0 = [i for i, bit in enumerate(best_solution) if bit == 0]\n",
    "group_1 = [i for i, bit in enumerate(best_solution) if bit == 1]\n",
    "\n",
    "print(f\"\\nGroup 0 ({len(group_0)} topics):\")\n",
    "for idx in group_0:\n",
    "    print(f\"  - {wiki_subset.iloc[idx]['title']}\")\n",
    "\n",
    "print(f\"\\nGroup 1 ({len(group_1)} topics):\")\n",
    "for idx in group_1:\n",
    "    print(f\"  - {wiki_subset.iloc[idx]['title']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION OF OPTIMIZATION RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "# Visualize the graph partition\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Create a simple visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot nodes\n",
    "node_positions = {}\n",
    "n_per_row = int(np.ceil(np.sqrt(n_topics)))\n",
    "for i in range(n_topics):\n",
    "    row = i // n_per_row\n",
    "    col = i % n_per_row\n",
    "    node_positions[i] = (col, -row)\n",
    "\n",
    "# Color nodes by partition\n",
    "colors = ['lightblue' if best_solution[i] == 0 else 'lightcoral' for i in range(n_topics)]\n",
    "\n",
    "# Draw edges\n",
    "for i in range(n_topics):\n",
    "    for j in range(i + 1, n_topics):\n",
    "        if adjacency_matrix[i, j] == 1:\n",
    "            x1, y1 = node_positions[i]\n",
    "            x2, y2 = node_positions[j]\n",
    "            # Color edge based on whether it's cut\n",
    "            edge_color = 'red' if best_solution[i] != best_solution[j] else 'gray'\n",
    "            ax.plot([x1, x2], [y1, y2], color=edge_color, linewidth=1, alpha=0.5)\n",
    "\n",
    "# Draw nodes\n",
    "for i in range(n_topics):\n",
    "    x, y = node_positions[i]\n",
    "    ax.scatter(x, y, s=500, c=colors[i], edgecolors='black', linewidth=2, zorder=3)\n",
    "    # Add label\n",
    "    title = wiki_subset.iloc[i]['title'][:20]  # Truncate long titles\n",
    "    ax.text(x, y, f'{i}', ha='center', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "ax.set_title('QAOA Optimal Partition of Historical Topics', fontsize=14, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "# Add legend\n",
    "group0_patch = mpatches.Patch(color='lightblue', label='Group 0')\n",
    "group1_patch = mpatches.Patch(color='lightcoral', label='Group 1')\n",
    "ax.legend(handles=[group0_patch, group1_patch], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QUANTUM OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nThe QAOA algorithm has found an optimal partition of historical topics\")\n",
    "print(\"that maximizes the number of edges (similarities) between the two groups.\")\n",
    "print(\"\\nThis demonstrates how quantum algorithms can solve combinatorial\")\n",
    "print(\"optimization problems that are difficult for classical computers!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f2ada",
   "metadata": {},
   "source": [
    "# Summary and Conclusions\n",
    "\n",
    "## What We've Demonstrated:\n",
    "\n",
    "### 1. Classical Machine Learning (Explainable ML)\n",
    "- **K-Nearest Neighbors (KNN)**: Simple, intuitive classification based on similar examples\n",
    "- **Support Vector Machine (SVM)**: Optimal decision boundary finding\n",
    "- Both methods are beginner-friendly and explainable\n",
    "- Achieved good classification accuracy on gladiator survival prediction\n",
    "- Demonstrated how to understand WHY predictions are made\n",
    "\n",
    "### 2. Data Integration\n",
    "- Connected gladiator data with historical Wikipedia periods\n",
    "- Analyzed survival rates across different Roman historical eras\n",
    "- Showed how combining datasets provides deeper insights\n",
    "- Demonstrated the value of contextualizing data with historical information\n",
    "\n",
    "### 3. Quantum Optimization\n",
    "- **Quantum Approximate Optimization Algorithm (QAOA)** for finding optimal partitions\n",
    "- Solved Max-Cut problem on historical Wikipedia topic similarity graph\n",
    "- Found optimal groupings that maximize inter-group connections\n",
    "- Demonstrated quantum advantage potential for combinatorial optimization\n",
    "\n",
    "## Key Concepts Used:\n",
    "\n",
    "### Classical ML:\n",
    "1. **KNN**: Classification based on similarity to training examples\n",
    "2. **SVM**: Finding optimal decision boundaries\n",
    "3. **Explainability**: Understanding model predictions\n",
    "\n",
    "### Quantum Computing:\n",
    "1. **Quantum Superposition**: Qubits can exist in multiple states simultaneously\n",
    "2. **Quantum Entanglement**: Qubits can be correlated in ways impossible classically\n",
    "3. **Variational Quantum Algorithms**: Hybrid quantum-classical optimization\n",
    "4. **Quantum Measurement**: Extracting classical information from quantum states\n",
    "\n",
    "## Future Directions:\n",
    "\n",
    "- Scale quantum optimization to larger graphs with more qubits\n",
    "- Use real quantum hardware (IBM Quantum, IonQ, etc.)\n",
    "- Explore other quantum optimization algorithms\n",
    "- Apply to other optimization problems (Traveling Salesman, Portfolio Optimization)\n",
    "- Further integrate datasets to find more historical insights\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum_computing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
