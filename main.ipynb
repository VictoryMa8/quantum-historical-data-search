{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "QUANTUM COMPUTING PROJECT: Historical Data Analysis with PennyLane\n",
    "================================================================================\n",
    "\n",
    "This notebook demonstrates the power of quantum computing through:\n",
    "1. Quantum Machine Learning (QML): Predicting gladiator survival using Variational Quantum Classifiers\n",
    "2. Quantum Optimization: Finding optimal groupings in historical Wikipedia data using QAOA\n",
    "\n",
    "Author: Quantum Historical Data Search Project\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# PennyLane imports for quantum computing\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "pnp.random.seed(42)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"QUANTUM COMPUTING PROJECT: Historical Data Analysis\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nLibraries imported successfully!\")\n",
    "print(f\"PennyLane version: {qml.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e704307f",
   "metadata": {},
   "source": [
    "# Part 1: Data Loading and Exploration\n",
    "\n",
    "Let's start by loading and exploring our historical datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a987e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gladiator dataset\n",
    "# This dataset contains information about ancient Roman gladiators\n",
    "gladiator_df = pd.read_csv(\"gladiator_data.csv\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"GLADIATOR DATASET OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Shape: {gladiator_df.shape}\")\n",
    "print(f\"\\nColumns: {list(gladiator_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(gladiator_df.head())\n",
    "print(f\"\\nSurvival rate: {gladiator_df['Survived'].mean():.2%}\")\n",
    "print(f\"\\nMissing values:\\n{gladiator_df.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d552a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wikipedia historical dataset\n",
    "wiki_df = pd.read_csv(\"wiki_data.csv\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"WIKIPEDIA HISTORICAL DATASET OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Shape: {wiki_df.shape}\")\n",
    "print(f\"\\nColumns: {list(wiki_df.columns)}\")\n",
    "print(f\"\\nFirst few entries:\")\n",
    "print(wiki_df[['title', 'relevans', 'popularity', 'ranking']].head(10))\n",
    "print(f\"\\nMissing values:\\n{wiki_df.isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5372c05b",
   "metadata": {},
   "source": [
    "# Part 2: Quantum Machine Learning (QML) - Gladiator Survival Prediction\n",
    "\n",
    "## Overview\n",
    "We'll use a **Variational Quantum Classifier (VQC)** to predict whether a gladiator survived based on their characteristics. This demonstrates how quantum circuits can learn patterns in classical data.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Variational Quantum Circuits (VQC)**: Parameterized quantum circuits that can be trained like neural networks\n",
    "- **Feature Encoding**: Mapping classical data to quantum states using angle encoding\n",
    "- **Variational Layers**: Parameterized rotations that learn optimal transformations\n",
    "- **Measurement**: Extracting classical predictions from quantum states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA PREPROCESSING FOR QML\n",
    "# ============================================================================\n",
    "\n",
    "# Select relevant numerical and categorical features for prediction\n",
    "# We'll use a mix of features that could influence survival\n",
    "\n",
    "# Numerical features\n",
    "numerical_features = ['Age', 'Height', 'Weight', 'Wins', 'Losses', \n",
    "                      'Public Favor', 'Mental Resilience', 'Battle Experience']\n",
    "\n",
    "# Categorical features to encode\n",
    "categorical_features = ['Category', 'Special Skills', 'Weapon of Choice', \n",
    "                        'Patron Wealth', 'Equipment Quality', 'Health Status']\n",
    "\n",
    "# Create a working copy\n",
    "df_work = gladiator_df.copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_work[col + '_encoded'] = le.fit_transform(df_work[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Combine features\n",
    "feature_cols = numerical_features + [col + '_encoded' for col in categorical_features]\n",
    "X = df_work[feature_cols].values\n",
    "y = df_work['Survived'].astype(int).values  # Convert True/False to 1/0\n",
    "\n",
    "# Normalize features (important for quantum circuits)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# For quantum circuits, we need to limit the number of features\n",
    "# Quantum circuits with many qubits become computationally expensive\n",
    "# We'll use the top 8 most important features (for 8 qubits)\n",
    "# In practice, you could use feature selection techniques\n",
    "\n",
    "# Select top 8 features based on correlation with survival\n",
    "correlations = []\n",
    "for i, col in enumerate(feature_cols):\n",
    "    corr = np.abs(np.corrcoef(X[:, i], y)[0, 1])\n",
    "    correlations.append((i, corr, col))\n",
    "\n",
    "correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "selected_indices = [idx for idx, _, _ in correlations[:8]]\n",
    "selected_features = [name for _, _, name in correlations[:8]]\n",
    "\n",
    "print(\"Selected features for quantum circuit:\")\n",
    "for i, (idx, corr, name) in enumerate(correlations[:8]):\n",
    "    print(f\"{i+1}. {name}: correlation = {corr:.4f}\")\n",
    "\n",
    "# Extract selected features\n",
    "X_selected = X_scaled[:, selected_indices]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Features per sample: {X_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d704a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QUANTUM CIRCUIT DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "# Number of qubits = number of features\n",
    "n_qubits = X_train.shape[1]\n",
    "n_layers = 2  # Number of variational layers (more layers = more expressivity)\n",
    "\n",
    "# Create a quantum device\n",
    "# 'default.qubit' is PennyLane's built-in simulator\n",
    "# For real quantum hardware, you could use 'qiskit.ibmq' or other providers\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "\n",
    "print(f\"Quantum device: {dev.name}\")\n",
    "print(f\"Number of qubits: {n_qubits}\")\n",
    "print(f\"Number of layers: {n_layers}\")\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def quantum_circuit(features, weights):\n",
    "    \"\"\"\n",
    "    Variational Quantum Circuit for classification.\n",
    "    \n",
    "    Args:\n",
    "        features: Input features (classical data) - shape (n_qubits,)\n",
    "        weights: Trainable parameters - shape (n_layers, n_qubits, 3)\n",
    "                 Each layer has n_qubits rotations with 3 parameters (RX, RY, RZ)\n",
    "    \n",
    "    Returns:\n",
    "        Expectation value of Pauli-Z operator on the first qubit\n",
    "        This gives us a value between -1 and 1, which we'll interpret as a prediction\n",
    "    \"\"\"\n",
    "    # STEP 1: Feature Encoding (Angle Encoding)\n",
    "    # Encode classical features into quantum states by rotating qubits\n",
    "    # Each feature value becomes a rotation angle\n",
    "    for i in range(n_qubits):\n",
    "        # Apply a rotation around Y-axis based on feature value\n",
    "        # Using arctan to map features to [-π/2, π/2] range\n",
    "        qml.RY(np.arctan(features[i]), wires=i)\n",
    "    \n",
    "    # STEP 2: Variational Layers (Parameterized Quantum Gates)\n",
    "    # These layers contain trainable parameters that will be optimized\n",
    "    for layer in range(n_layers):\n",
    "        # Entangling layer: Create quantum correlations between qubits\n",
    "        # This allows the circuit to learn complex relationships\n",
    "        for i in range(n_qubits - 1):\n",
    "            qml.CNOT(wires=[i, i + 1])  # Controlled-NOT gate creates entanglement\n",
    "        \n",
    "        # Rotation layer: Apply parameterized rotations\n",
    "        # These are the \"weights\" that will be trained\n",
    "        for i in range(n_qubits):\n",
    "            qml.Rot(weights[layer, i, 0],  # Rotation around X-axis\n",
    "                   weights[layer, i, 1],  # Rotation around Y-axis\n",
    "                   weights[layer, i, 2],  # Rotation around Z-axis\n",
    "                   wires=i)\n",
    "    \n",
    "    # STEP 3: Measurement\n",
    "    # Measure the expectation value of Pauli-Z operator on first qubit\n",
    "    # This gives us a real-valued output that we can use for classification\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "# Initialize random weights\n",
    "# Shape: (n_layers, n_qubits, 3) - 3 rotation angles per qubit per layer\n",
    "weights = pnp.random.uniform(0, 2 * np.pi, size=(n_layers, n_qubits, 3), requires_grad=True)\n",
    "\n",
    "print(f\"\\nWeight shape: {weights.shape}\")\n",
    "print(f\"Total trainable parameters: {np.prod(weights.shape)}\")\n",
    "\n",
    "# Test the circuit with a sample input\n",
    "sample_features = X_train[0]\n",
    "sample_output = quantum_circuit(sample_features, weights)\n",
    "print(f\"\\nSample output (expectation value): {sample_output:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QUANTUM CLASSIFIER MODEL\n",
    "# ============================================================================\n",
    "\n",
    "def quantum_classifier(weights, bias, features):\n",
    "    \"\"\"\n",
    "    Quantum classifier that combines quantum circuit output with classical bias.\n",
    "    \n",
    "    Args:\n",
    "        weights: Quantum circuit parameters\n",
    "        bias: Classical bias term\n",
    "        features: Input features\n",
    "    \n",
    "    Returns:\n",
    "        Prediction value (before sigmoid activation)\n",
    "    \"\"\"\n",
    "    # Get quantum circuit output\n",
    "    quantum_output = quantum_circuit(features, weights)\n",
    "    \n",
    "    # Combine with bias and return\n",
    "    # The quantum output is in [-1, 1], we scale it and add bias\n",
    "    return quantum_output + bias\n",
    "\n",
    "def cost_function(weights, bias, X, y):\n",
    "    \"\"\"\n",
    "    Cost function for training the quantum classifier.\n",
    "    Uses mean squared error between predictions and true labels.\n",
    "    \n",
    "    Args:\n",
    "        weights: Quantum circuit parameters\n",
    "        bias: Classical bias term\n",
    "        X: Training features\n",
    "        y: Training labels (0 or 1)\n",
    "    \n",
    "    Returns:\n",
    "        Mean squared error\n",
    "    \"\"\"\n",
    "    predictions = [quantum_classifier(weights, bias, x) for x in X]\n",
    "    predictions = pnp.array(predictions)\n",
    "    \n",
    "    # Convert quantum output [-1, 1] to probability [0, 1]\n",
    "    # Using sigmoid-like transformation: (x + 1) / 2\n",
    "    probabilities = (predictions + 1) / 2\n",
    "    \n",
    "    # Mean squared error\n",
    "    loss = pnp.mean((probabilities - y) ** 2)\n",
    "    return loss\n",
    "\n",
    "# Initialize bias\n",
    "bias = pnp.array(0.0, requires_grad=True)\n",
    "\n",
    "print(\"Quantum classifier model defined!\")\n",
    "print(f\"Initial cost: {cost_function(weights, bias, X_train[:10], y_train[:10]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING THE QUANTUM CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "# Use PennyLane's optimizer (Adam optimizer)\n",
    "opt = qml.AdamOptimizer(stepsize=0.1)\n",
    "\n",
    "# Training parameters\n",
    "n_epochs = 30\n",
    "batch_size = 20  # Process data in batches to reduce computation time\n",
    "\n",
    "# Store training history\n",
    "cost_history = []\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING QUANTUM CLASSIFIER\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Epochs: {n_epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(\"\\nTraining...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    # Shuffle training data\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    X_shuffled = X_train[indices]\n",
    "    y_shuffled = y_train[indices]\n",
    "    \n",
    "    epoch_cost = 0\n",
    "    n_batches = len(X_train) // batch_size\n",
    "    \n",
    "    # Process in batches\n",
    "    for batch_idx in range(n_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "        X_batch = X_shuffled[start_idx:end_idx]\n",
    "        y_batch = y_shuffled[start_idx:end_idx]\n",
    "        \n",
    "        # Define cost function for this batch\n",
    "        def batch_cost(w, b):\n",
    "            return cost_function(w, b, X_batch, y_batch)\n",
    "        \n",
    "        # Optimize weights and bias\n",
    "        weights, bias = opt.step(batch_cost, weights, bias)\n",
    "        \n",
    "        # Calculate cost\n",
    "        batch_cost_val = batch_cost(weights, bias)\n",
    "        epoch_cost += batch_cost_val\n",
    "    \n",
    "    avg_cost = epoch_cost / n_batches\n",
    "    cost_history.append(avg_cost)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Cost: {avg_cost:.4f}\")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cost_history, 'b-', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Cost (MSE)', fontsize=12)\n",
    "plt.title('Quantum Classifier Training History', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f019f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATING THE QUANTUM CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "def predict(weights, bias, X):\n",
    "    \"\"\"\n",
    "    Make predictions using the trained quantum classifier.\n",
    "    \n",
    "    Args:\n",
    "        weights: Trained quantum circuit parameters\n",
    "        bias: Trained bias term\n",
    "        X: Features to predict on\n",
    "    \n",
    "    Returns:\n",
    "        Binary predictions (0 or 1)\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        output = quantum_classifier(weights, bias, x)\n",
    "        # Convert quantum output to probability\n",
    "        prob = (output + 1) / 2\n",
    "        # Threshold at 0.5\n",
    "        predictions.append(1 if prob > 0.5 else 0)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = predict(weights, bias, X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"QUANTUM CLASSIFIER RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Died', 'Survived']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Died', 'Survived'],\n",
    "            yticklabels=['Died', 'Survived'])\n",
    "plt.title('Quantum Classifier Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Compare with baseline (always predict majority class)\n",
    "baseline_accuracy = max(y_test.mean(), 1 - y_test.mean())\n",
    "print(f\"\\nBaseline Accuracy (majority class): {baseline_accuracy:.4f}\")\n",
    "print(f\"Quantum Improvement: {accuracy - baseline_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0830b1",
   "metadata": {},
   "source": [
    "# Part 3: Quantum Optimization - Finding Optimal Historical Topic Groupings\n",
    "\n",
    "## Overview\n",
    "We'll use the **Quantum Approximate Optimization Algorithm (QAOA)** to find optimal groupings of historical Wikipedia topics. This demonstrates how quantum computers can solve combinatorial optimization problems.\n",
    "\n",
    "### Key Concepts:\n",
    "- **QAOA**: A quantum algorithm for solving optimization problems\n",
    "- **Max-Cut Problem**: Finding optimal partitions in a graph (we'll create a graph from topic similarities)\n",
    "- **Cost Hamiltonian**: Quantum representation of the optimization objective\n",
    "- **Variational Optimization**: Finding optimal parameters through classical optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e37d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PREPARING DATA FOR QUANTUM OPTIMIZATION\n",
    "# ============================================================================\n",
    "\n",
    "# For QAOA, we'll work with a smaller subset of Wikipedia entries\n",
    "# QAOA works best with smaller graphs (due to current quantum hardware limitations)\n",
    "n_topics = 20  # Number of topics to cluster\n",
    "\n",
    "# Select top N topics by popularity/ranking\n",
    "wiki_subset = wiki_df.nlargest(n_topics, 'popularity').copy()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"QUANTUM OPTIMIZATION: Historical Topic Clustering\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Selected {n_topics} topics for optimization\")\n",
    "print(f\"\\nSelected topics:\")\n",
    "for i, title in enumerate(wiki_subset['title'].head(10), 1):\n",
    "    print(f\"{i}. {title}\")\n",
    "\n",
    "# Create a similarity graph based on text content\n",
    "# We'll use simple keyword matching to create edges\n",
    "# In practice, you could use more sophisticated NLP techniques\n",
    "\n",
    "# Extract keywords from titles (simple approach)\n",
    "def extract_keywords(text):\n",
    "    \"\"\"Extract keywords from text (simplified).\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # Convert to lowercase and split\n",
    "    words = str(text).lower().split()\n",
    "    # Filter out very short words\n",
    "    keywords = [w for w in words if len(w) > 3]\n",
    "    return set(keywords)\n",
    "\n",
    "# Build similarity matrix\n",
    "similarity_matrix = np.zeros((n_topics, n_topics))\n",
    "\n",
    "for i in range(n_topics):\n",
    "    keywords_i = extract_keywords(wiki_subset.iloc[i]['title'])\n",
    "    for j in range(i + 1, n_topics):\n",
    "        keywords_j = extract_keywords(wiki_subset.iloc[j]['title'])\n",
    "        # Jaccard similarity\n",
    "        intersection = len(keywords_i & keywords_j)\n",
    "        union = len(keywords_i | keywords_j)\n",
    "        similarity = intersection / union if union > 0 else 0\n",
    "        similarity_matrix[i, j] = similarity\n",
    "        similarity_matrix[j, i] = similarity\n",
    "\n",
    "# Create adjacency matrix for graph\n",
    "# Connect topics with similarity > threshold\n",
    "threshold = 0.1\n",
    "adjacency_matrix = (similarity_matrix > threshold).astype(int)\n",
    "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
    "\n",
    "# Count edges\n",
    "n_edges = np.sum(adjacency_matrix) // 2\n",
    "print(f\"\\nGraph statistics:\")\n",
    "print(f\"  Nodes (topics): {n_topics}\")\n",
    "print(f\"  Edges (connections): {n_edges}\")\n",
    "print(f\"  Average degree: {np.sum(adjacency_matrix) / n_topics:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70224d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QAOA IMPLEMENTATION FOR MAX-CUT PROBLEM\n",
    "# ============================================================================\n",
    "\n",
    "# Max-Cut Problem: Partition graph into two groups to maximize edges between groups\n",
    "# This is a classic optimization problem that QAOA can solve efficiently\n",
    "\n",
    "# Create quantum device\n",
    "n_qubits_opt = n_topics\n",
    "dev_opt = qml.device('default.qubit', wires=n_qubits_opt)\n",
    "\n",
    "def maxcut_cost_hamiltonian(adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Create the cost Hamiltonian for Max-Cut problem.\n",
    "    \n",
    "    Max-Cut: Maximize the number of edges between two partitions.\n",
    "    Cost Hamiltonian: Sum over edges (1 - Z_i Z_j) / 2\n",
    "    where Z_i, Z_j are Pauli-Z operators on qubits i and j\n",
    "    \n",
    "    Args:\n",
    "        adjacency_matrix: Graph adjacency matrix\n",
    "    \n",
    "    Returns:\n",
    "        Cost Hamiltonian as a PennyLane observable and list of edges\n",
    "    \"\"\"\n",
    "    # List of observables (one for each edge)\n",
    "    observables = []\n",
    "    coeffs = []\n",
    "    edges = []  # Store edges for easier circuit construction\n",
    "    \n",
    "    for i in range(n_qubits_opt):\n",
    "        for j in range(i + 1, n_qubits_opt):\n",
    "            if adjacency_matrix[i, j] == 1:  # If there's an edge\n",
    "                # Cost for edge (i,j): (1 - Z_i Z_j) / 2\n",
    "                # We want to maximize this, so minimize its negative\n",
    "                obs = qml.PauliZ(i) @ qml.PauliZ(j)\n",
    "                observables.append(obs)\n",
    "                coeffs.append(-0.5)  # Negative because we'll minimize\n",
    "                edges.append((i, j))\n",
    "    \n",
    "    # Constant term (doesn't affect optimization)\n",
    "    constant = np.sum(adjacency_matrix) / 2\n",
    "    \n",
    "    return qml.Hamiltonian(coeffs, observables), constant, edges\n",
    "\n",
    "# Create cost Hamiltonian\n",
    "cost_hamiltonian, constant, edges = maxcut_cost_hamiltonian(adjacency_matrix)\n",
    "\n",
    "print(f\"Cost Hamiltonian created with {len(edges)} terms (edges)\")\n",
    "print(f\"Constant term: {constant}\")\n",
    "\n",
    "def mixer_hamiltonian(n_qubits):\n",
    "    \"\"\"\n",
    "    Create the mixer Hamiltonian for QAOA.\n",
    "    Mixer: Sum of Pauli-X operators on all qubits\n",
    "    This allows the algorithm to explore the solution space.\n",
    "    \n",
    "    Args:\n",
    "        n_qubits: Number of qubits\n",
    "    \n",
    "    Returns:\n",
    "        Mixer Hamiltonian\n",
    "    \"\"\"\n",
    "    coeffs = []\n",
    "    observables = []\n",
    "    for i in range(n_qubits):\n",
    "        coeffs.append(1.0)\n",
    "        observables.append(qml.PauliX(i))\n",
    "    return qml.Hamiltonian(coeffs, observables)\n",
    "\n",
    "mixer_hamiltonian = mixer_hamiltonian(n_qubits_opt)\n",
    "print(f\"Mixer Hamiltonian created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QAOA CIRCUIT\n",
    "# ============================================================================\n",
    "\n",
    "def qaoa_layer(gamma, beta, edges_list):\n",
    "    \"\"\"\n",
    "    One layer of QAOA circuit.\n",
    "    \n",
    "    QAOA alternates between:\n",
    "    1. Applying cost Hamiltonian (with parameter gamma)\n",
    "    2. Applying mixer Hamiltonian (with parameter beta)\n",
    "    \n",
    "    Args:\n",
    "        gamma: Parameter for cost Hamiltonian evolution\n",
    "        beta: Parameter for mixer Hamiltonian evolution\n",
    "        edges_list: List of edges (i, j) in the graph\n",
    "    \"\"\"\n",
    "    # Apply cost Hamiltonian evolution\n",
    "    # Our cost Hamiltonian is: H = sum over edges (-0.5 * Z_i * Z_j)\n",
    "    # We want to apply: exp(-i*gamma*H) = exp(i*gamma*0.5*sum(Z_i*Z_j))\n",
    "    # For each edge, apply exp(i*gamma*0.5*Z_i*Z_j)\n",
    "    # Using CNOT-RZ-CNOT decomposition: exp(i*theta*Z_i*Z_j) = CNOT RZ(-2*theta) CNOT\n",
    "    for i, j in edges_list:\n",
    "        # CNOT-RZ-CNOT decomposition for exp(i*gamma*0.5*Z_i*Z_j)\n",
    "        # theta = gamma*0.5, so rotation angle = -2*theta = -gamma\n",
    "        qml.CNOT(wires=[i, j])\n",
    "        qml.RZ(-gamma, wires=j)\n",
    "        qml.CNOT(wires=[i, j])\n",
    "    \n",
    "    # Apply mixer Hamiltonian evolution\n",
    "    # Mixer is sum of Pauli-X: exp(-i*beta*sum(X_i)) = product of RX(2*beta)\n",
    "    for i in range(n_qubits_opt):\n",
    "        qml.RX(2 * beta, wires=i)\n",
    "\n",
    "def qaoa_circuit(params, cost_ham, mixer_ham):\n",
    "    \"\"\"\n",
    "    Full QAOA circuit.\n",
    "    \n",
    "    Args:\n",
    "        params: Array of parameters [gamma_1, beta_1, gamma_2, beta_2, ...]\n",
    "        cost_ham: Cost Hamiltonian (for measurement)\n",
    "        mixer_ham: Mixer Hamiltonian (not used directly, kept for API consistency)\n",
    "    \n",
    "    Returns:\n",
    "        Expectation value of cost Hamiltonian\n",
    "    \"\"\"\n",
    "    # Initialize in uniform superposition |+⟩^⊗n\n",
    "    for i in range(n_qubits_opt):\n",
    "        qml.Hadamard(wires=i)\n",
    "    \n",
    "    # Apply QAOA layers\n",
    "    p = len(params) // 2  # Number of layers\n",
    "    for i in range(p):\n",
    "        gamma = params[2 * i]\n",
    "        beta = params[2 * i + 1]\n",
    "        qaoa_layer(gamma, beta, edges)\n",
    "    \n",
    "    # Measure expectation value of cost Hamiltonian\n",
    "    return qml.expval(cost_ham)\n",
    "\n",
    "# Create QAOA QNode\n",
    "qaoa_qnode = qml.QNode(qaoa_circuit, dev_opt)\n",
    "\n",
    "# Number of QAOA layers (depth)\n",
    "p = 2  # More layers = better approximation, but more parameters to optimize\n",
    "\n",
    "# Initialize parameters randomly\n",
    "init_params = pnp.random.uniform(0, 2 * np.pi, size=2 * p, requires_grad=True)\n",
    "\n",
    "print(f\"QAOA circuit created\")\n",
    "print(f\"  Number of layers (p): {p}\")\n",
    "print(f\"  Number of parameters: {len(init_params)}\")\n",
    "print(f\"  Initial parameters: {init_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIMIZING QAOA PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "def qaoa_cost(params):\n",
    "    \"\"\"\n",
    "    Cost function for QAOA optimization.\n",
    "    We want to minimize the expectation value of the cost Hamiltonian.\n",
    "    \n",
    "    Args:\n",
    "        params: QAOA parameters\n",
    "    \n",
    "    Returns:\n",
    "        Expectation value (to be minimized)\n",
    "    \"\"\"\n",
    "    return qaoa_qnode(params, cost_hamiltonian, mixer_hamiltonian)\n",
    "\n",
    "# Optimize QAOA parameters\n",
    "opt_qaoa = qml.AdamOptimizer(stepsize=0.1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"OPTIMIZING QAOA PARAMETERS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "n_iterations = 50\n",
    "params = init_params\n",
    "cost_history_qaoa = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Optimize\n",
    "    params, cost_val = opt_qaoa.step_and_cost(qaoa_cost, params)\n",
    "    cost_history_qaoa.append(cost_val)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Iteration {i + 1}/{n_iterations}, Cost: {cost_val:.4f}\")\n",
    "\n",
    "print(\"\\nOptimization completed!\")\n",
    "print(f\"Final cost: {cost_history_qaoa[-1]:.4f}\")\n",
    "\n",
    "# Plot optimization history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cost_history_qaoa, 'r-', linewidth=2)\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Cost (Expectation Value)', fontsize=12)\n",
    "plt.title('QAOA Optimization History', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXTRACTING OPTIMAL SOLUTION\n",
    "# ============================================================================\n",
    "\n",
    "# Sample from the optimized QAOA circuit to get the solution\n",
    "n_samples = 1000\n",
    "\n",
    "def sample_solution(params, n_samples):\n",
    "    \"\"\"\n",
    "    Sample bitstrings from QAOA circuit and find the best solution.\n",
    "    \n",
    "    Args:\n",
    "        params: Optimized QAOA parameters\n",
    "        n_samples: Number of samples to draw\n",
    "    \n",
    "    Returns:\n",
    "        Best bitstring and its cost\n",
    "    \"\"\"\n",
    "    # Create a circuit that measures in computational basis\n",
    "    @qml.qnode(dev_opt)\n",
    "    def measurement_circuit(params):\n",
    "        # Apply QAOA circuit\n",
    "        for i in range(n_qubits_opt):\n",
    "            qml.Hadamard(wires=i)\n",
    "        \n",
    "        p = len(params) // 2\n",
    "        for i in range(p):\n",
    "            gamma = params[2 * i]\n",
    "            beta = params[2 * i + 1]\n",
    "            qaoa_layer(gamma, beta, edges)\n",
    "        \n",
    "        # Measure all qubits\n",
    "        return [qml.sample(qml.PauliZ(i)) for i in range(n_qubits_opt)]\n",
    "    \n",
    "    # Sample bitstrings\n",
    "    samples = []\n",
    "    for _ in range(n_samples):\n",
    "        sample = measurement_circuit(params)\n",
    "        # Convert from {-1, +1} to {0, 1}\n",
    "        bitstring = [(1 - s) // 2 for s in sample]\n",
    "        samples.append(bitstring)\n",
    "    \n",
    "    # Calculate cost for each sample\n",
    "    def calculate_cut_cost(bitstring):\n",
    "        \"\"\"Calculate the cut value for a given partition.\"\"\"\n",
    "        cut_value = 0\n",
    "        for i in range(n_qubits_opt):\n",
    "            for j in range(i + 1, n_qubits_opt):\n",
    "                if adjacency_matrix[i, j] == 1:\n",
    "                    # Edge is cut if nodes are in different partitions\n",
    "                    if bitstring[i] != bitstring[j]:\n",
    "                        cut_value += 1\n",
    "        return cut_value\n",
    "    \n",
    "    # Find best solution\n",
    "    best_bitstring = None\n",
    "    best_cost = -1\n",
    "    \n",
    "    for bitstring in samples:\n",
    "        cost = calculate_cut_cost(bitstring)\n",
    "        if cost > best_cost:\n",
    "            best_cost = cost\n",
    "            best_bitstring = bitstring\n",
    "    \n",
    "    return best_bitstring, best_cost\n",
    "\n",
    "print(\"Sampling solutions from optimized QAOA circuit...\")\n",
    "best_solution, best_cut_value = sample_solution(params, n_samples)\n",
    "\n",
    "print(f\"\\nOptimal partition found!\")\n",
    "print(f\"Cut value (edges between partitions): {best_cut_value} out of {n_edges} total edges\")\n",
    "print(f\"Cut ratio: {best_cut_value / n_edges:.2%}\")\n",
    "\n",
    "# Display the partition\n",
    "group_0 = [i for i, bit in enumerate(best_solution) if bit == 0]\n",
    "group_1 = [i for i, bit in enumerate(best_solution) if bit == 1]\n",
    "\n",
    "print(f\"\\nGroup 0 ({len(group_0)} topics):\")\n",
    "for idx in group_0:\n",
    "    print(f\"  - {wiki_subset.iloc[idx]['title']}\")\n",
    "\n",
    "print(f\"\\nGroup 1 ({len(group_1)} topics):\")\n",
    "for idx in group_1:\n",
    "    print(f\"  - {wiki_subset.iloc[idx]['title']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION OF OPTIMIZATION RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "# Visualize the graph partition\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Create a simple visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot nodes\n",
    "node_positions = {}\n",
    "n_per_row = int(np.ceil(np.sqrt(n_topics)))\n",
    "for i in range(n_topics):\n",
    "    row = i // n_per_row\n",
    "    col = i % n_per_row\n",
    "    node_positions[i] = (col, -row)\n",
    "\n",
    "# Color nodes by partition\n",
    "colors = ['lightblue' if best_solution[i] == 0 else 'lightcoral' for i in range(n_topics)]\n",
    "\n",
    "# Draw edges\n",
    "for i in range(n_topics):\n",
    "    for j in range(i + 1, n_topics):\n",
    "        if adjacency_matrix[i, j] == 1:\n",
    "            x1, y1 = node_positions[i]\n",
    "            x2, y2 = node_positions[j]\n",
    "            # Color edge based on whether it's cut\n",
    "            edge_color = 'red' if best_solution[i] != best_solution[j] else 'gray'\n",
    "            ax.plot([x1, x2], [y1, y2], color=edge_color, linewidth=1, alpha=0.5)\n",
    "\n",
    "# Draw nodes\n",
    "for i in range(n_topics):\n",
    "    x, y = node_positions[i]\n",
    "    ax.scatter(x, y, s=500, c=colors[i], edgecolors='black', linewidth=2, zorder=3)\n",
    "    # Add label\n",
    "    title = wiki_subset.iloc[i]['title'][:20]  # Truncate long titles\n",
    "    ax.text(x, y, f'{i}', ha='center', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "ax.set_title('QAOA Optimal Partition of Historical Topics', fontsize=14, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "# Add legend\n",
    "group0_patch = mpatches.Patch(color='lightblue', label='Group 0')\n",
    "group1_patch = mpatches.Patch(color='lightcoral', label='Group 1')\n",
    "ax.legend(handles=[group0_patch, group1_patch], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QUANTUM OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nThe QAOA algorithm has found an optimal partition of historical topics\")\n",
    "print(\"that maximizes the number of edges (similarities) between the two groups.\")\n",
    "print(\"\\nThis demonstrates how quantum algorithms can solve combinatorial\")\n",
    "print(\"optimization problems that are difficult for classical computers!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f2ada",
   "metadata": {},
   "source": [
    "# Summary and Conclusions\n",
    "\n",
    "## What We've Demonstrated:\n",
    "\n",
    "### 1. Quantum Machine Learning (QML)\n",
    "- **Variational Quantum Classifier (VQC)** for predicting gladiator survival\n",
    "- Used quantum feature encoding and variational layers\n",
    "- Achieved classification accuracy on historical gladiator data\n",
    "- Demonstrated how quantum circuits can learn patterns in classical data\n",
    "\n",
    "### 2. Quantum Optimization\n",
    "- **Quantum Approximate Optimization Algorithm (QAOA)** for finding optimal partitions\n",
    "- Solved Max-Cut problem on historical Wikipedia topic similarity graph\n",
    "- Found optimal groupings that maximize inter-group connections\n",
    "- Demonstrated quantum advantage potential for combinatorial optimization\n",
    "\n",
    "## Key Quantum Computing Concepts Used:\n",
    "\n",
    "1. **Quantum Superposition**: Qubits can exist in multiple states simultaneously\n",
    "2. **Quantum Entanglement**: Qubits can be correlated in ways impossible classically\n",
    "3. **Variational Quantum Algorithms**: Hybrid quantum-classical optimization\n",
    "4. **Quantum Measurement**: Extracting classical information from quantum states\n",
    "\n",
    "## Future Directions:\n",
    "\n",
    "- Scale to larger datasets with more qubits\n",
    "- Use real quantum hardware (IBM Quantum, IonQ, etc.)\n",
    "- Explore other QML architectures (Quantum Neural Networks, Quantum Kernels)\n",
    "- Apply to other optimization problems (Traveling Salesman, Portfolio Optimization)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum_computing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
